I understand the task and requirements. Let's think through this step-by-step before generating the functions:

1. Information provided in processed_states:
   - Agent positions, directions, and whether they're carrying shelves
   - Locations of empty shelves, workstations, and return points
   - Whether agents can move forward or place shelves

2. Strategy analysis:
   - Prioritize delivering empty shelves to workstations
   - Efficiently return shelves after delivery
   - Explore when no immediate tasks are available
   - Coordinate between agents to avoid conflicts and maximize efficiency

Now, let's generate the two functions based on this analysis:

<code>
def planning_function(processed_state):
    """
    Determines optimal tasks for each agent based on the current state.
    
    Args:
        processed_state: A dictionary containing global information for each agent and the positions of empty shelves observed by any agent.

    Returns:
        dict: Optimal tasks for each agent ('random explore','empty shelf','workstation','return')
    """
    llm_tasks = {}
    agent_infos = processed_state['agent_infos']
    empty_shelves_pos = processed_state.get('empty_shelves_pos', [])
    workstation_locations = processed_state.get('workstation location', [])
    return_locations = processed_state.get('return location', [])

    for i, agent_info in enumerate(agent_infos):
        agent_key = f"agent_{i}"
        is_carrying_shelf = agent_info['is_carrying_shelf']
        status_of_carried_shelf = agent_info.get('status of carried shelf', False)

        if is_carrying_shelf:
            if status_of_carried_shelf:
                # If carrying a non-empty shelf, return it
                llm_tasks[agent_key] = "return"
            else:
                # If carrying an empty shelf, deliver to workstation
                llm_tasks[agent_key] = "workstation"
        else:
            if empty_shelves_pos:
                # If there are empty shelves, go to the nearest one
                llm_tasks[agent_key] = "empty shelf"
            else:
                # If no empty shelves are visible, explore
                llm_tasks[agent_key] = "random explore"

    return llm_tasks

def compute_reward(processed_state, llm_actions, actions):
    """
    Calculate rewards based on the tasks assigned and their outcomes.
    
    Args:
        processed_state: returned from function process_state(state, p, f)
        llm_actions (dict): dictionary of list of integers which means the suggest actions from llm for each agent.
        actions (dict): dictionary of a integer action that actually perform by each agent.
        
    Returns:
        reward: Dict containing rewards for each agent.
    """
    reward = {}
    agent_infos = processed_state['agent_infos']
    workstation_locations = processed_state.get('workstation location', [])
    return_locations = processed_state.get('return location', [])

    for agent_key, action in actions.items():
        agent_index = int(agent_key.split('_')[1])
        agent_info = agent_infos[agent_index]
        suggested_actions = llm_actions.get(agent_key, [])

        base_reward = 0
        
        # Reward for following LLM suggestions
        if action in suggested_actions:
            base_reward += 0.1

        # Reward for loading/unloading shelves
        if action == 4:  # Load/Unload action
            if agent_info['is_carrying_shelf']:
                if any(agent_info['location'] == loc for loc in workstation_locations):
                    base_reward += 1.0  # Reward for delivering to workstation
                elif any(agent_info['location'] == loc for loc in return_locations):
                    base_reward += 0.5  # Reward for returning shelf
            else:
                base_reward += 0.3  # Reward for picking up a shelf

        # Penalty for no movement when not at a workstation or return location
        if action == 0 and not (any(agent_info['location'] == loc for loc in workstation_locations) or 
                                any(agent_info['location'] == loc for loc in return_locations)):
            base_reward -= 0.1

        reward[agent_key] = base_reward

    return reward
</code>

These functions work together to improve agent cooperation:

1. The planning function assigns tasks based on the current state, prioritizing delivering empty shelves and efficient returns.

2. The reward function encourages:
   - Following LLM suggestions
   - Picking up, delivering, and returning shelves
   - Avoiding unnecessary idling

This approach should lead to improved cooperation between agents in the RWARE environment.